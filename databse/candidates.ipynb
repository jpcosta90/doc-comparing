{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import requests\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Caminho do banco de dados\n",
    "DB_PATH = \"document_comparisons.db\"\n",
    "\n",
    "# Função para inicializar a tabela Candidatas\n",
    "def initialize_candidates_table():\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Candidatas (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        doc1_id TEXT NOT NULL,\n",
    "        doc2_id TEXT NOT NULL,\n",
    "        similarity_score FLOAT NOT NULL,\n",
    "        comparison_date DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "        UNIQUE(doc1_id, doc2_id)\n",
    "    )\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# Função para buscar documentos da API\n",
    "def search_documents(collection=None, max_results=10, start=0):\n",
    "    \"\"\"\n",
    "    Busca documentos da API.\n",
    "    \"\"\"\n",
    "    base_url = \"https://metadata.idl.ucsf.edu/solr/ltdl3/query\"\n",
    "    query = f\"collection:{collection}\" if collection else \"*:*\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"wt\": \"json\",\n",
    "        \"rows\": max_results,\n",
    "        \"start\": start\n",
    "    }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get(\"response\", {}).get(\"docs\", [])\n",
    "    else:\n",
    "        raise ValueError(f\"Erro na API: {response.status_code}\")\n",
    "\n",
    "# Função para gerar URL do arquivo TIF\n",
    "def get_tif_url(doc_id):\n",
    "    return f\"https://download.industrydocuments.ucsf.edu/{doc_id[0]}/{doc_id[1]}/{doc_id[2]}/{doc_id[3]}/{doc_id}/{doc_id}.tif\"\n",
    "\n",
    "# Função para carregar documento TIF\n",
    "def load_tif(doc_id):\n",
    "    tif_url = get_tif_url(doc_id)\n",
    "    response = requests.get(tif_url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        img = Image.open(io.BytesIO(response.content))\n",
    "        return img.copy()  # Retorna apenas a primeira página\n",
    "    else:\n",
    "        raise ValueError(f\"Erro ao carregar o arquivo TIF: {response.status_code}\")\n",
    "\n",
    "# Função para comparar imagens\n",
    "def compare_pil_images(img1, img2):\n",
    "    img1_gray = np.array(img1.convert(\"L\"))\n",
    "    img2_gray = np.array(img2.convert(\"L\"))\n",
    "\n",
    "    if img1_gray.shape != img2_gray.shape:\n",
    "        img2_gray = np.array(img2.resize(img1.size).convert(\"L\"))\n",
    "\n",
    "    similarity_index, _ = ssim(img1_gray, img2_gray, full=True)\n",
    "    return similarity_index\n",
    "\n",
    "# Função para salvar uma comparação candidata\n",
    "def save_candidate(doc1_id, doc2_id, similarity_score):\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        cursor.execute(\"\"\"\n",
    "        INSERT INTO Candidatas (doc1_id, doc2_id, similarity_score)\n",
    "        VALUES (?, ?, ?)\n",
    "        \"\"\", (doc1_id, doc2_id, similarity_score))\n",
    "    except sqlite3.IntegrityError:\n",
    "        pass  # Evita duplicatas\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# Função para contar as linhas da tabela\n",
    "def count_candidates():\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM Candidatas\")\n",
    "    count = cursor.fetchone()[0]\n",
    "\n",
    "    conn.close()\n",
    "    return count\n",
    "\n",
    "# Processo de busca e alimentação da tabela\n",
    "def search_and_feed_candidates(collection=None, max_results=10):\n",
    "    initialize_candidates_table()\n",
    "\n",
    "    start = 0  # Início da busca na API\n",
    "\n",
    "    while count_candidates() < 1000:\n",
    "        # Buscar documentos da API\n",
    "        try:\n",
    "            documents = search_documents(collection=collection, max_results=max_results, start=start)\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            break\n",
    "\n",
    "        # Realizar comparações entre pares de documentos\n",
    "        for i, doc1 in enumerate(documents):\n",
    "            for doc2 in documents[i+1:]:\n",
    "                try:\n",
    "                    doc1_id = doc1.get(\"id\")\n",
    "                    doc2_id = doc2.get(\"id\")\n",
    "\n",
    "                    # Carregar imagens dos documentos\n",
    "                    img1 = load_tif(doc1_id)\n",
    "                    img2 = load_tif(doc2_id)\n",
    "\n",
    "                    # Comparar as imagens\n",
    "                    similarity_score = compare_pil_images(img1, img2)\n",
    "\n",
    "                    # Salvar no banco se a similaridade for maior que 0.86\n",
    "                    if similarity_score > 0.85:\n",
    "                        save_candidate(doc1_id, doc2_id, similarity_score)\n",
    "\n",
    "                        print(f\"Gravado: {doc1_id} vs {doc2_id} - Similaridade: {similarity_score:.2f}\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro na comparação: {e}\")\n",
    "\n",
    "                # Checar se alcançamos 1000 candidatos\n",
    "                if count_candidates() >= 1000:\n",
    "                    print(\"Tabela de candidatos preenchida com 1000 comparações.\")\n",
    "                    return\n",
    "\n",
    "        start += max_results  # Avançar para a próxima página de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_candidates_table():\n",
    "    \"\"\"\n",
    "    Remove a tabela Candidatas do banco de dados.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"DROP TABLE IF EXISTS Candidatas\")\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_candidates_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('one_page_document_comparisons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>file1</th>\n",
       "      <th>file2</th>\n",
       "      <th>same_pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>180</td>\n",
       "      <td>ffcj0179</td>\n",
       "      <td>gkdj0179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181</td>\n",
       "      <td>ffcj0179</td>\n",
       "      <td>hkdj0179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>182</td>\n",
       "      <td>ffcj0179</td>\n",
       "      <td>jrxx0179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183</td>\n",
       "      <td>ffcj0179</td>\n",
       "      <td>lzcj0179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>184</td>\n",
       "      <td>ffcj0179</td>\n",
       "      <td>rldj0179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>1871</td>\n",
       "      <td>gnyx0222</td>\n",
       "      <td>xnyx0222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>1876</td>\n",
       "      <td>hnyx0222</td>\n",
       "      <td>xnyx0222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>1885</td>\n",
       "      <td>lkbn0220</td>\n",
       "      <td>mkbn0220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>1886</td>\n",
       "      <td>lkbn0220</td>\n",
       "      <td>nkbn0220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>1888</td>\n",
       "      <td>mkbn0220</td>\n",
       "      <td>nkbn0220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0     file1     file2  same_pattern\n",
       "0           180  ffcj0179  gkdj0179             1\n",
       "1           181  ffcj0179  hkdj0179             1\n",
       "2           182  ffcj0179  jrxx0179             1\n",
       "3           183  ffcj0179  lzcj0179             1\n",
       "4           184  ffcj0179  rldj0179             1\n",
       "..          ...       ...       ...           ...\n",
       "311        1871  gnyx0222  xnyx0222             1\n",
       "312        1876  hnyx0222  xnyx0222             1\n",
       "313        1885  lkbn0220  mkbn0220             1\n",
       "314        1886  lkbn0220  nkbn0220             1\n",
       "315        1888  mkbn0220  nkbn0220             1\n",
       "\n",
       "[316 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['same_pattern'] == 1].reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho do banco de dados SQLite\n",
    "DB_PATH = \"document_comparisons.db\"\n",
    "\n",
    "# Função para remover o prefixo 'patternXX/' do caminho dos arquivos\n",
    "def clean_filename(filename):\n",
    "    \"\"\"\n",
    "    Remove o caminho do diretório e a extensão '.tif' do nome do arquivo.\n",
    "    \"\"\"\n",
    "    return filename.split(\"/\")[-1].replace(\".tif\", \"\")\n",
    "\n",
    "# Remover o prefixo do caminho dos arquivos\n",
    "df[\"file1\"] = df[\"file1\"].apply(clean_filename)\n",
    "df[\"file2\"] = df[\"file2\"].apply(clean_filename)\n",
    "\n",
    "# Inserir dados na tabela Candidatas\n",
    "def insert_comparisons(df, modelo=\"Manual Selection\"):\n",
    "    \"\"\"\n",
    "    Insere os dados da comparação na tabela 'Candidatas'.\n",
    "    \"\"\"\n",
    "    # Conectar ao banco de dados\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Verificar e criar a tabela, se não existir\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Candidatas (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        doc1_id TEXT NOT NULL,\n",
    "        doc2_id TEXT NOT NULL,\n",
    "        similarity_score FLOAT NOT NULL,\n",
    "        modelo TEXT NOT NULL,\n",
    "        comparison_date DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "        UNIQUE(doc1_id, doc2_id, modelo)\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    # Inserir dados no banco de dados\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            cursor.execute(\"\"\"\n",
    "            INSERT INTO Candidatas (doc1_id, doc2_id, similarity_score, modelo)\n",
    "            VALUES (?, ?, ?, ?)\n",
    "            \"\"\", (row[\"file1\"], row[\"file2\"], 1.0, modelo))  # Salva com score 1.0 como padrão\n",
    "        except sqlite3.IntegrityError:\n",
    "            print(f\"Duplicata ignorada: {row['file1']} - {row['file2']}\")\n",
    "\n",
    "    # Commit e fechar conexão\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(\"Dados inseridos com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados inseridos com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Executar a inserção\n",
    "insert_comparisons(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
