{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# URL base da API\n",
    "BASE_URL = \"https://metadata.idl.ucsf.edu/solr/ltdl3/query\"\n",
    "\n",
    "def get_total_documents(max_pages=1):\n",
    "    \"\"\"\n",
    "    Obtém a quantidade total de documentos disponíveis na API Solr, \n",
    "    aplicando um limite de páginas.\n",
    "\n",
    "    Args:\n",
    "        max_pages (int): Número máximo de páginas para filtrar os documentos. Padrão: 1.\n",
    "\n",
    "    Returns:\n",
    "        int: Número total de documentos disponíveis com o filtro aplicado.\n",
    "    \"\"\"\n",
    "    # Construção da query com filtros\n",
    "    query_parts = []\n",
    "    query_parts.append(f\"pages:[* TO {max_pages}]\")  # Filtro de número máximo de páginas\n",
    "    query = \" AND \".join(query_parts) if query_parts else \"*:*\"  # Query final\n",
    "\n",
    "    # Parâmetros da requisição\n",
    "    params = {\n",
    "        \"q\": query,         # Query construída manualmente\n",
    "        \"wt\": \"json\",       # Resposta em formato JSON\n",
    "        \"rows\": 0           # Não retorna documentos, apenas a contagem\n",
    "    }\n",
    "\n",
    "    # Requisição à API\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    if response.status_code == 200:\n",
    "        # Extrai o número total de documentos\n",
    "        total_documents = response.json().get(\"response\", {}).get(\"numFound\", 0)\n",
    "        return total_documents\n",
    "    else:\n",
    "        # Trata erros na requisição\n",
    "        print(f\"Erro {response.status_code} ao consultar o total de documentos.\")\n",
    "        print(f\"Mensagem de erro: {response.text}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade total de documentos disponíveis com até 1 página: 10435636\n",
      "Quantidade total de documentos disponíveis com até 5 páginas: 17356073\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "total_documents = get_total_documents()\n",
    "if total_documents is not None:\n",
    "    print(f\"Quantidade total de documentos disponíveis com até 1 página: {total_documents}\")\n",
    "else:\n",
    "    print(\"Falha ao obter o total de documentos.\")\n",
    "\n",
    "# Para consultar com um limite diferente de páginas\n",
    "total_documents_5_pages = get_total_documents(max_pages=5)\n",
    "if total_documents_5_pages is not None:\n",
    "    print(f\"Quantidade total de documentos disponíveis com até 5 páginas: {total_documents_5_pages}\")\n",
    "else:\n",
    "    print(\"Falha ao obter o total de documentos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para processar 10435636 documentos com lotes de 100, serão necessárias 104357 iterações.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def calculate_iterations(total_documents, max_results):\n",
    "    \"\"\"\n",
    "    Calcula o número de iterações necessárias para processar todos os documentos.\n",
    "\n",
    "    Args:\n",
    "        total_documents (int): O número total de documentos disponíveis na API.\n",
    "        max_results (int): O número máximo de documentos por lote (tamanho do lote).\n",
    "\n",
    "    Returns:\n",
    "        int: O número total de iterações necessárias.\n",
    "    \"\"\"\n",
    "    if max_results <= 0:\n",
    "        raise ValueError(\"max_results deve ser maior que zero.\")\n",
    "    if total_documents <= 0:\n",
    "        raise ValueError(\"total_documents deve ser maior que zero.\")\n",
    "    \n",
    "    # Calcula o número total de iterações\n",
    "    iterations = math.ceil(total_documents / max_results)\n",
    "    return iterations\n",
    "\n",
    "# Exemplo de uso\n",
    "try:\n",
    "    # total_documents = total_documents  # Número total de documentos (exemplo da API)\n",
    "    max_results = 100  # Tamanho do lote (exemplo)\n",
    "\n",
    "    iterations = calculate_iterations(total_documents, max_results)\n",
    "    print(f\"Para processar {total_documents} documentos com lotes de {max_results}, serão necessárias {iterations} iterações.\")\n",
    "except ValueError as e:\n",
    "    print(f\"Erro: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sqlite3\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# URL base da API\n",
    "BASE_URL = \"https://metadata.idl.ucsf.edu/solr/ltdl3/query\"\n",
    "DB_PATH = \"document_comparisons.db\"\n",
    "\n",
    "def initialize_database():\n",
    "    \"\"\"\n",
    "    Cria ou atualiza a tabela Collections_Types no banco de dados.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Criação ou atualização da tabela\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS Collections_Types (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        collection TEXT NOT NULL,\n",
    "        type TEXT NOT NULL,\n",
    "        count INTEGER NOT NULL,\n",
    "        cursorMark TEXT,\n",
    "        UNIQUE(collection, type)\n",
    "    )\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_collection_type(collection, doc_type, count, cursor_mark):\n",
    "    \"\"\"\n",
    "    Salva ou atualiza uma combinação collection/type com sua contagem de documentos e o cursorMark.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        cursor.execute(\"\"\"\n",
    "        INSERT INTO Collections_Types (collection, type, count, cursorMark)\n",
    "        VALUES (?, ?, ?, ?)\n",
    "        ON CONFLICT(collection, type) DO UPDATE SET \n",
    "            count = count + excluded.count,\n",
    "            cursorMark = excluded.cursorMark;\n",
    "        \"\"\", (collection, doc_type, count, cursor_mark))\n",
    "    except sqlite3.IntegrityError:\n",
    "        pass  # Evita duplicatas\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_combinations(max_pages=1, total_documents=10435636):\n",
    "    \"\"\"\n",
    "    Busca as combinações de collections e types diretamente em lotes usando cursorMark\n",
    "    e continua a partir de onde parou, baseado nos dados já armazenados.\n",
    "    \n",
    "    Parâmetros:\n",
    "        max_pages (int): Número máximo de páginas para filtrar os documentos na API (padrão: 1).\n",
    "    \"\"\"\n",
    "    start_time = datetime.now()\n",
    "    max_results = 100\n",
    "    total_documents = total_documents  # Substitua pelo número real, se disponível\n",
    "\n",
    "    # Conectar ao banco de dados\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Recuperar o último cursorMark e total de registros processados\n",
    "    cursor.execute(\"SELECT cursorMark FROM Collections_Types ORDER BY id DESC LIMIT 1\")\n",
    "    last_cursor_mark = cursor.fetchone()\n",
    "    cursor_mark = last_cursor_mark[0] if last_cursor_mark else \"*\"  # Define o ponto de partida\n",
    "\n",
    "    cursor.execute(\"SELECT SUM(count) FROM Collections_Types\")\n",
    "    total_processed = cursor.fetchone()[0] or 0  # Total de registros já processados\n",
    "\n",
    "    print(f\"Iniciando processamento a partir do cursorMark: {cursor_mark}\")\n",
    "    print(f\"Progresso anterior: {total_processed} documentos processados ({(total_processed / total_documents) * 100:.2f}%).\")\n",
    "\n",
    "    # Processar os dados\n",
    "    while True:\n",
    "        # Construção da query com filtros\n",
    "        query_parts = [f\"pages:[* TO {max_pages}]\"]  # Filtro de número máximo de páginas\n",
    "        query = \" AND \".join(query_parts) if query_parts else \"*:*\"\n",
    "\n",
    "        params = {\n",
    "            \"q\": query,               # Query construída manualmente\n",
    "            \"fl\": \"collection,type\",  # Retorna apenas os campos desejados\n",
    "            \"wt\": \"json\",             # Formato da resposta\n",
    "            \"rows\": max_results,      # Tamanho do lote\n",
    "            \"cursorMark\": cursor_mark,  # Paginação com cursor\n",
    "            \"sort\": \"id asc\"          # Ordenação necessária para usar cursorMark\n",
    "        }\n",
    "\n",
    "        response = requests.get(BASE_URL, params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            docs = data.get(\"response\", {}).get(\"docs\", [])\n",
    "            next_cursor_mark = data.get(\"nextCursorMark\", cursor_mark)\n",
    "\n",
    "            if not docs:\n",
    "                break  # Sai do loop se não houver mais documentos\n",
    "\n",
    "            # Processa as combinações de collection e type\n",
    "            counts = {}\n",
    "            for doc in docs:\n",
    "                collections = doc.get(\"collection\")\n",
    "                doc_types = doc.get(\"type\")\n",
    "\n",
    "                # Trata collection e type como listas\n",
    "                if not isinstance(collections, list):\n",
    "                    collections = [collections]\n",
    "                if not isinstance(doc_types, list):\n",
    "                    doc_types = [doc_types]\n",
    "\n",
    "                # Conta as combinações\n",
    "                for collection in collections:\n",
    "                    for doc_type in doc_types:\n",
    "                        if collection and doc_type:\n",
    "                            key = (collection, doc_type)\n",
    "                            counts[key] = counts.get(key, 0) + 1\n",
    "\n",
    "            # Salva cada combinação no banco de dados com o cursorMark\n",
    "            for (collection, doc_type), count in counts.items():\n",
    "                try:\n",
    "                    cursor.execute(\"\"\"\n",
    "                        INSERT INTO Collections_Types (collection, type, count, cursorMark)\n",
    "                        VALUES (?, ?, ?, ?)\n",
    "                        ON CONFLICT(collection, type) DO UPDATE SET\n",
    "                            count = count + excluded.count,\n",
    "                            cursorMark = excluded.cursorMark\n",
    "                    \"\"\", (collection, doc_type, count, cursor_mark))\n",
    "                except sqlite3.Error as e:\n",
    "                    print(f\"Erro ao salvar no banco de dados: {e}\")\n",
    "            conn.commit()\n",
    "\n",
    "            # Atualiza o total de registros processados\n",
    "            total_processed += len(docs)\n",
    "\n",
    "            # Atualiza progresso no terminal\n",
    "            elapsed_time = datetime.now() - start_time\n",
    "            percent_complete = (total_processed / total_documents) * 100\n",
    "            print(f\"\\rProcessando... Cursor atual: {cursor_mark}, \"\n",
    "                  f\"Documentos processados: {total_processed}, \"\n",
    "                  f\"Progresso: {percent_complete:.2f}%, \"\n",
    "                  f\"Tempo decorrido: {elapsed_time}\", end=\"\")\n",
    "\n",
    "            # Atualiza o cursor para a próxima iteração\n",
    "            if cursor_mark == next_cursor_mark:  # Se não houver progresso no cursor, encerra\n",
    "                break\n",
    "            cursor_mark = next_cursor_mark\n",
    "\n",
    "        elif response.status_code == 403:\n",
    "            print(f\"Erro 403: {response.text}\")\n",
    "            print(\"Aguardando 2 segundos antes de continuar...\")\n",
    "            time.sleep(2)\n",
    "\n",
    "        else:\n",
    "            print(f\"Erro {response.status_code} ao buscar combinações.\")\n",
    "            print(f\"Mensagem de erro: {response.text}\")\n",
    "            break\n",
    "\n",
    "    print(\"\\nProcessamento concluído!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando processamento a partir do cursorMark: AoEoZnFrazAyMzc=\n",
      "Progresso anterior: 871110 documentos processados (8.35%).\n",
      "Processando... Cursor atual: AoEoZnJidjAyNTk=, Documentos processados: 894910, Progresso: 8.58%, Tempo decorrido: 0:05:18.490162"
     ]
    }
   ],
   "source": [
    "# Inicializar banco de dados e executar busca\n",
    "initialize_database()\n",
    "fetch_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A tabela 'Collections_Types' não existe no banco de dados.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "# Verificar se a tabela existe e carregar os dados\n",
    "query_check = \"SELECT name FROM sqlite_master WHERE type='table' AND name='Collections_Types';\"\n",
    "if not pd.read_sql_query(query_check, conn).empty:\n",
    "    # Lê os dados da tabela no DataFrame do Pandas\n",
    "    df = pd.read_sql_query(\"SELECT * FROM Collections_Types;\", conn)\n",
    "\n",
    "    # Verifica se há dados na tabela\n",
    "    if not df.empty:\n",
    "        print(f\"Tabela 'Collections_Types' contém {len(df)} registros:\")\n",
    "    else:\n",
    "        print(\"A tabela 'Collections_Types' está vazia.\")\n",
    "else:\n",
    "    print(\"A tabela 'Collections_Types' não existe no banco de dados.\")\n",
    "\n",
    "# Fechar a conexão\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_table():\n",
    "    \"\"\"\n",
    "    Remove a tabela Collections_Types do banco de dados.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    try:\n",
    "        # Dropar a tabela sem verificação prévia\n",
    "        cursor.execute(\"DROP TABLE IF EXISTS Collections_Types;\")\n",
    "        conn.commit()\n",
    "        print(\"Tabela 'Collections_Types' foi removida (se existia).\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao dropar a tabela: {e}\")\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela 'Collections_Types' foi removida (se existia).\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "drop_table()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
